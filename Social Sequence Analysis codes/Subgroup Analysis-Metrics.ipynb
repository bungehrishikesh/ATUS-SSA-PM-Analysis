{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d0d09f-d02e-4d35-85c8-5eb0c1ad0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "FILE_PATH = \"ATUS_2010_Cluster_joined_main_dataset.csv\"\n",
    "\n",
    "# Match column names exactly (case + spaces)\n",
    "CASE_ID_COL   = \"Case ID\"\n",
    "GENDER_COL    = \"Gender\"\n",
    "ACTIVITY_COL  = \"Activity\"\n",
    "START_COL     = \"Start Timestamp\"\n",
    "END_COL       = \"End Timestamp\"\n",
    "\n",
    "# For wide 144-slot format (probably not used here)\n",
    "SLOT_PREFIX   = \"slot_\"\n",
    "\n",
    "DIARY_START_HOUR = 4\n",
    "BIN_MINUTES = 10\n",
    "N_SLOTS = int((24*60)//BIN_MINUTES)  # 144\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e805dc14-33c0-4651-96bf-2c802308ae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected format: LONG (events with times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16672\\3601246552.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[START_COL] = pd.to_datetime(df[START_COL], errors=\"coerce\")\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_16672\\3601246552.py:34: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[END_COL]   = pd.to_datetime(df[END_COL], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Load & detect schema (Updated) ===\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Clean headers & trim whitespace in key columns\n",
    "df.columns = df.columns.str.strip()\n",
    "for c in [GENDER_COL, ACTIVITY_COL]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# Normalize gender labels\n",
    "def _norm_gender(x):\n",
    "    x = str(x).strip().lower()\n",
    "    if x in [\"m\", \"male\", \"man\"]:\n",
    "        return \"Male\"\n",
    "    if x in [\"f\", \"female\", \"woman\", \"women\"]:\n",
    "        return \"Female\"\n",
    "    return str(x) if x else \"Unknown\"\n",
    "\n",
    "df[GENDER_COL] = df[GENDER_COL].apply(_norm_gender)\n",
    "\n",
    "# Detect wide vs long\n",
    "slot_cols = [c for c in df.columns if c.startswith(SLOT_PREFIX)]\n",
    "is_wide = len(slot_cols) >= N_SLOTS\n",
    "\n",
    "print(\"Detected format:\", \"WIDE (144 slots)\" if is_wide else \"LONG (events with times)\")\n",
    "\n",
    "if is_wide:\n",
    "    slot_cols = sorted(slot_cols, key=lambda x: int(x.replace(SLOT_PREFIX,\"\")))\n",
    "else:\n",
    "    for col in [CASE_ID_COL, ACTIVITY_COL, START_COL, END_COL]:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    df[START_COL] = pd.to_datetime(df[START_COL], errors=\"coerce\")\n",
    "    df[END_COL]   = pd.to_datetime(df[END_COL], errors=\"coerce\")\n",
    "    if df[[START_COL, END_COL]].isna().any().any():\n",
    "        raise ValueError(\"Found NaT in start/end times. Please fix/clean time columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d980a9-fd4a-46d5-ba1b-255ab223f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Helpers ===\n",
    "\n",
    "def longest_run_length(labels):\n",
    "    max_run = 0\n",
    "    current_label = None\n",
    "    current_len = 0\n",
    "    for lab in labels:\n",
    "        if pd.isna(lab):\n",
    "            current_label = None\n",
    "            current_len = 0\n",
    "            continue\n",
    "        if lab == current_label:\n",
    "            current_len += 1\n",
    "        else:\n",
    "            current_label = lab\n",
    "            current_len = 1\n",
    "        max_run = max(max_run, current_len)\n",
    "    return max_run\n",
    "\n",
    "def shannon_entropy(labels):\n",
    "    labs = [x for x in labels if pd.notna(x)]\n",
    "    if len(labs) == 0:\n",
    "        return 0.0, 0.0\n",
    "    counts = Counter(labs)\n",
    "    total = sum(counts.values())\n",
    "    ps = [v/total for v in counts.values()]\n",
    "    H = -sum(p*log(p) for p in ps)\n",
    "    k = len(counts)\n",
    "    H_norm = H / log(k) if k > 1 else 0.0\n",
    "    return H, H_norm\n",
    "\n",
    "def compute_complexity(sequence_activities, bin_minutes=10):\n",
    "    seq = list(sequence_activities)\n",
    "    transitions = sum(\n",
    "        1 for i in range(1, len(seq))\n",
    "        if pd.notna(seq[i-1]) and pd.notna(seq[i]) and seq[i] != seq[i-1]\n",
    "    )\n",
    "    unique_count = len({x for x in seq if pd.notna(x)})\n",
    "    max_run_slots = longest_run_length(seq)\n",
    "    max_run_minutes = max_run_slots * bin_minutes\n",
    "    H, H_norm = shannon_entropy(seq)\n",
    "    return {\n",
    "        \"Transitions\": transitions,\n",
    "        \"Unique\": unique_count,\n",
    "        \"Max run (min)\": max_run_minutes,\n",
    "        \"Entropy\": H,\n",
    "        \"Entropy (norm)\": H_norm\n",
    "    }\n",
    "\n",
    "def build_10min_sequence_from_long(df_case, diary_start_hour=4, bin_minutes=10):\n",
    "    first_ts = df_case[START_COL].min()\n",
    "    if pd.isna(first_ts):\n",
    "        return [np.nan]*N_SLOTS\n",
    "\n",
    "    day0 = first_ts.normalize()\n",
    "    diary_start = day0 + pd.Timedelta(hours=diary_start_hour)\n",
    "    if first_ts < diary_start:\n",
    "        diary_start -= pd.Timedelta(days=1)\n",
    "    diary_end = diary_start + pd.Timedelta(hours=24)\n",
    "\n",
    "    rows = []\n",
    "    for _, r in df_case.iterrows():\n",
    "        s = max(r[START_COL], diary_start)\n",
    "        e = min(r[END_COL], diary_end)\n",
    "        if pd.isna(s) or pd.isna(e) or e <= s:\n",
    "            continue\n",
    "        rows.append((s, e, r[ACTIVITY_COL]))\n",
    "\n",
    "    if not rows:\n",
    "        return [np.nan]*N_SLOTS\n",
    "\n",
    "    seq = []\n",
    "    for k in range(N_SLOTS):\n",
    "        t = diary_start + pd.Timedelta(minutes=k*bin_minutes)\n",
    "        label = np.nan\n",
    "        for (s, e, act) in rows:\n",
    "            if s <= t < e:\n",
    "                label = act\n",
    "                break\n",
    "        seq.append(label)\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25090335-6a13-4915-8715-da578b6e02ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 146)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>slot_0</th>\n",
       "      <th>slot_1</th>\n",
       "      <th>slot_2</th>\n",
       "      <th>slot_3</th>\n",
       "      <th>slot_4</th>\n",
       "      <th>slot_5</th>\n",
       "      <th>slot_6</th>\n",
       "      <th>slot_7</th>\n",
       "      <th>slot_8</th>\n",
       "      <th>...</th>\n",
       "      <th>slot_135</th>\n",
       "      <th>slot_136</th>\n",
       "      <th>slot_137</th>\n",
       "      <th>slot_138</th>\n",
       "      <th>slot_139</th>\n",
       "      <th>slot_140</th>\n",
       "      <th>slot_141</th>\n",
       "      <th>slot_142</th>\n",
       "      <th>slot_143</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'20100101100520</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'20100101100658</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'20100101100920</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'20100101101236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'20100101101423</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>Sleeping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Case ID    slot_0    slot_1    slot_2    slot_3    slot_4  \\\n",
       "0  '20100101100520  Sleeping  Sleeping  Sleeping  Sleeping  Sleeping   \n",
       "1  '20100101100658  Sleeping  Sleeping  Sleeping  Sleeping  Sleeping   \n",
       "2  '20100101100920  Sleeping  Sleeping  Sleeping  Sleeping  Sleeping   \n",
       "3  '20100101101236       NaN       NaN       NaN       NaN       NaN   \n",
       "4  '20100101101423  Sleeping  Sleeping  Sleeping  Sleeping  Sleeping   \n",
       "\n",
       "     slot_5    slot_6    slot_7    slot_8  ...  slot_135  slot_136  slot_137  \\\n",
       "0  Sleeping  Sleeping  Sleeping  Sleeping  ...       NaN       NaN       NaN   \n",
       "1  Sleeping  Sleeping  Sleeping  Sleeping  ...       NaN       NaN       NaN   \n",
       "2  Sleeping  Sleeping  Sleeping  Sleeping  ...       NaN       NaN       NaN   \n",
       "3       NaN       NaN       NaN       NaN  ...  Sleeping  Sleeping  Sleeping   \n",
       "4  Sleeping  Sleeping  Sleeping  Sleeping  ...       NaN       NaN       NaN   \n",
       "\n",
       "   slot_138  slot_139  slot_140  slot_141  slot_142  slot_143  Gender  \n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN  Female  \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN    Male  \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN  Female  \n",
       "3  Sleeping  Sleeping  Sleeping  Sleeping  Sleeping  Sleeping    Male  \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN  Female  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 4: Build sequences per case (long format only) ===\n",
    "if not is_wide:\n",
    "    sequences = {}\n",
    "    for cid, g in df.groupby(CASE_ID_COL, sort=False):\n",
    "        sequences[cid] = build_10min_sequence_from_long(\n",
    "            g.sort_values(START_COL),\n",
    "            diary_start_hour=DIARY_START_HOUR,\n",
    "            bin_minutes=BIN_MINUTES\n",
    "        )\n",
    "    seq_df = pd.DataFrame.from_dict(sequences, orient=\"index\")\n",
    "    seq_df.columns = [f\"{SLOT_PREFIX}{i}\" for i in range(N_SLOTS)]\n",
    "    seq_df.index.name = CASE_ID_COL\n",
    "    seq_df.reset_index(inplace=True)\n",
    "\n",
    "    gender_map = df.drop_duplicates(subset=[CASE_ID_COL])[ [CASE_ID_COL, GENDER_COL] ]\n",
    "    wide_df = seq_df.merge(gender_map, on=CASE_ID_COL, how=\"left\")\n",
    "else:\n",
    "    wide_df = df[[CASE_ID_COL, GENDER_COL] + slot_cols].copy()\n",
    "\n",
    "print(wide_df.shape)\n",
    "wide_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42abf44-fef6-4b4f-8ea5-584f17b28b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male vs Female — Complexity metrics (averages):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subgroup</th>\n",
       "      <th>Transitions</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Max run (min)</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Entropy (norm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>13.599</td>\n",
       "      <td>6.177</td>\n",
       "      <td>269.1</td>\n",
       "      <td>1.351</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>11.412</td>\n",
       "      <td>5.654</td>\n",
       "      <td>280.2</td>\n",
       "      <td>1.233</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subgroup  Transitions  Unique  Max run (min)  Entropy  Entropy (norm)\n",
       "0   Female       13.599   6.177          269.1    1.351           0.713\n",
       "1     Male       11.412   5.654          280.2    1.233           0.673"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: complexity_by_gender.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5: Per-case metrics and Gender averages ===\n",
    "def compute_metrics_row(row, slot_columns):\n",
    "    seq = [row[c] for c in slot_columns]\n",
    "    return compute_complexity(seq, bin_minutes=BIN_MINUTES)\n",
    "\n",
    "slot_cols_use = slot_cols if is_wide else [f\"{SLOT_PREFIX}{i}\" for i in range(N_SLOTS)]\n",
    "\n",
    "metrics = wide_df.apply(lambda r: pd.Series(compute_metrics_row(r, slot_cols_use)), axis=1)\n",
    "metrics_df = pd.concat([wide_df[[CASE_ID_COL, GENDER_COL]].reset_index(drop=True), metrics], axis=1)\n",
    "\n",
    "agg = (metrics_df\n",
    "       .groupby(GENDER_COL, dropna=False)\n",
    "       .agg({\n",
    "           \"Transitions\": \"mean\",\n",
    "           \"Unique\": \"mean\",\n",
    "           \"Max run (min)\": \"mean\",\n",
    "           \"Entropy\": \"mean\",\n",
    "           \"Entropy (norm)\": \"mean\"\n",
    "       })\n",
    "       .rename_axis(\"Subgroup\")\n",
    "       .reset_index())\n",
    "\n",
    "agg_rounded = agg.copy()\n",
    "for col in [\"Transitions\", \"Unique\", \"Entropy\", \"Entropy (norm)\"]:\n",
    "    agg_rounded[col] = agg_rounded[col].round(3)\n",
    "agg_rounded[\"Max run (min)\"] = agg_rounded[\"Max run (min)\"].round(1)\n",
    "\n",
    "print(\"Male vs Female — Complexity metrics (averages):\")\n",
    "display(agg_rounded)\n",
    "\n",
    "OUT_PATH = \"complexity_by_gender.csv\"\n",
    "agg_rounded.to_csv(OUT_PATH, index=False)\n",
    "print(f\"Saved: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e66b5ce-64a4-486a-b3dd-799180e97d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday vs Weekend — Complexity metrics (averages):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subgroup</th>\n",
       "      <th>Transitions</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Max run (min)</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Entropy (norm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weekday</td>\n",
       "      <td>13.279</td>\n",
       "      <td>6.179</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weekend</td>\n",
       "      <td>12.208</td>\n",
       "      <td>5.772</td>\n",
       "      <td>256.5</td>\n",
       "      <td>1.301</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subgroup  Transitions  Unique  Max run (min)  Entropy  Entropy (norm)\n",
       "0  Weekday       13.279   6.179          292.0    1.306           0.685\n",
       "1  Weekend       12.208   5.772          256.5    1.301           0.708"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: complexity_by_daytype.csv\n",
      "Saved: complexity_per_case_daytype.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure DayType column exists and is trimmed\n",
    "DAYTYPE_COL = \"DayType\"\n",
    "if DAYTYPE_COL not in df.columns:\n",
    "    raise ValueError(\"Missing 'DayType' column in the raw data.\")\n",
    "\n",
    "# Make a per-case DayType mapping (from the long/original df), then join to metrics_df\n",
    "daytype_map = (df[[CASE_ID_COL, DAYTYPE_COL]]\n",
    "               .drop_duplicates(subset=[CASE_ID_COL])\n",
    "               .copy())\n",
    "daytype_map[DAYTYPE_COL] = daytype_map[DAYTYPE_COL].astype(str).str.strip().str.title()\n",
    "\n",
    "# Attach DayType to per-case metrics (metrics_df was created in Cell 5)\n",
    "metrics_daytype = metrics_df.merge(daytype_map, on=CASE_ID_COL, how=\"left\")\n",
    "\n",
    "# Aggregate by DayType\n",
    "agg_day = (metrics_daytype\n",
    "           .groupby(DAYTYPE_COL, dropna=False)\n",
    "           .agg({\n",
    "               \"Transitions\": \"mean\",\n",
    "               \"Unique\": \"mean\",\n",
    "               \"Max run (min)\": \"mean\",\n",
    "               \"Entropy\": \"mean\",\n",
    "               \"Entropy (norm)\": \"mean\"\n",
    "           })\n",
    "           .rename_axis(\"Subgroup\")\n",
    "           .reset_index())\n",
    "\n",
    "# Round for presentation\n",
    "agg_day_rounded = agg_day.copy()\n",
    "for col in [\"Transitions\", \"Unique\", \"Entropy\", \"Entropy (norm)\"]:\n",
    "    agg_day_rounded[col] = agg_day_rounded[col].round(3)\n",
    "agg_day_rounded[\"Max run (min)\"] = agg_day_rounded[\"Max run (min)\"].round(1)\n",
    "\n",
    "print(\"Weekday vs Weekend — Complexity metrics (averages):\")\n",
    "display(agg_day_rounded)\n",
    "\n",
    "# Save\n",
    "agg_day_rounded.to_csv(\"complexity_by_daytype.csv\", index=False)\n",
    "print(\"Saved: complexity_by_daytype.csv\")\n",
    "\n",
    "# (Optional) save per-case with DayType for robustness checks\n",
    "per_case_daytype = metrics_daytype.copy()\n",
    "for col in [\"Transitions\", \"Unique\", \"Entropy\", \"Entropy (norm)\"]:\n",
    "    per_case_daytype[col] = per_case_daytype[col].round(3)\n",
    "per_case_daytype[\"Max run (min)\"] = per_case_daytype[\"Max run (min)\"].round(1)\n",
    "\n",
    "per_case_daytype.to_csv(\"complexity_per_case_daytype.csv\", index=False)\n",
    "print(\"Saved: complexity_per_case_daytype.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071fe19-f4e9-402c-bb31-41e6f58758a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
